AI Think Tank


# Product requirements document

## Background and goals

The app supports Design Thinking Workshops by turning problem statements into structured solution proposals and evidence-based debates. Five agents participate: Solution, Proponent, Opponent, Analyst, and Moderator. The aims are faster ideation, clearer trade-offs, practical outputs, and a reusable knowledge base.

## Target users

* Facilitators run debates, manage sessions, upload context, and export results.
* Participants submit problem statements, review debates, vote on arguments, and read summaries.

## Agent configuration

* **Context and grounding**

  * Facilitators can upload grounding material before a session, such as briefs, market scans, and policies.
  * Agents prioritise grounding material over open web sources, then trusted third-party sources, then general web.
  * Grounding scope can be set to ‘Internal only’, ‘Internal first’, or ‘Open web’.
  * All factual claims by the Analyst must include source citations.

* **Tone and persona controls**

  * Per-agent sliders and presets, for example:

    * Proponent: visionary ↔ conservative, customer-led ↔ product-led.
    * Opponent: risk-averse ↔ tolerant, cost-focused ↔ quality-focused.
    * Analyst: depth of evidence, confidence threshold for claims.
    * Moderator: terse ↔ detailed, decision-oriented ↔ neutral.
    * Solution Agent: innovative ↔ incremental, speed ↔ rigour.

* **Research mode**

  * Quick mode uses summaries and existing knowledge for speed.
  * Deep mode performs targeted retrieval across the grounding corpus and approved web connectors.

## User stories and use cases

* As a participant, I can submit a problem statement by text or speech.
* As a facilitator, I can upload grounding material and set agent tones before the session.
* As the Solution Agent, I can propose one or more structured solutions that are feasible and scoped.
* As the Proponent and Opponent, I can present points and direct rebuttals on each point.
* As the Analyst, I can attach evidence to specific points of contention and answer top participant questions.
* As the Moderator, I can produce a concise summary that reflects debate dynamics and participant sentiment.
* As a facilitator, I can regenerate any agent’s output, then edit and annotate the final summary before export.
* As a participant, I can vote on arguments and browse the library of past debates.

## Functional requirements

### Core features

1. **Session setup**

   * Upload grounding files and links, choose research mode, and set agent tones.
   * Configure the number of points per side and the number of rebuttal rounds.

2. **Problem input**

   * Text input and speech-to-text.
   * Facilitator approval gate starts the cycle.

3. **Solution generation**

   * Solution Agent proposes one to two solutions with structure: objective, approach, enablers, risks, expected impact, quick win vs longer play.
   * ‘Regenerate’ and ‘Refine’ with guided prompts.

4. **Debate and rebuttal**

   * Point-by-point flow:

     * Proponent presents Point N.
     * Opponent produces a direct rebuttal to Point N.
     * Repeat for a configured number of points.
   * Participants can upvote or downvote each argument in real time.
   * No live interjections that interrupt turns.

5. **Analysis**

   * Analyst attaches evidence to specific points and top-voted participant questions queued during the debate.
   * Each claim includes a citation and confidence note.

6. **Summary**

   * Moderator produces a balanced synthesis that references: strongest pro points, strongest cons, evidence highlights, participant sentiment, and decision prompts.
   * Facilitator can ‘Edit and annotate’ before export.

7. **Outputs**

   * Text: clear, concise, formatted sections with bullet points.
   * Audio: natural voices, optional distinct voice per agent, adjustable speed.
   * Visual debate map: flow from solution to points, rebuttals, and attached evidence nodes.

8. **Library**

   * Automatic archival with versioning, tags, workshop, outcomes, and engagement scores.
   * Advanced filters: theme tags, outcome status, research mode, date, most-voted arguments.
   * Quick links to solution, debate map, and summary.

### Quality control and iteration

* ‘Regenerate’ available per agent output.
* Guardrails: grounding priority, maximum hallucination risk, minimum evidence threshold for Analyst claims.
* Facilitator edits and annotations before export are captured as a final version.

## Non-functional requirements

* **Performance**

  * End-to-end cycle target under two minutes in Quick mode, under four minutes in Deep mode.
* **Scalability**

  * Multiple workshops in parallel across accounts, one active debate per session.
* **Accessibility**

  * Mobile-first responsive layout, captions for audio, keyboard navigation, screen reader support.
* **Security and privacy**

  * Grounding content stays within the tenant.
  * Role-based access for session materials and library.
  * Clear data retention settings per workspace.
* **Reliability**

  * Autosave for session state and drafts.
  * Retry and graceful fallback if a connector is unavailable.

## System architecture overview

* **Frontend**

  * Web app using a component library suited to rapid scanning and threaded views.
  * Later native mobile apps share the orchestration API.

* **Backend orchestration**

  * Agent controller service manages turn order, rebuttal rounds, and timing.
  * Retrieval service indexes grounding content into a vector store with metadata and permissions.
  * Evidence service handles citation formatting and confidence scoring.
  * Audio service handles TTS and STT.

* **Data layer**

  * Object storage for uploads, vector store for embeddings, relational store for sessions, votes, summaries, and versions.

* **Connectors**

  * File uploads, approved web search, and optional knowledge bases.
  * Connector allow-list managed by administrators.

## Updated workshop flow

1. **Setup**

   * Upload grounding material, set tones, choose Quick or Deep, and set rebuttal configuration.

2. **Problem input**

   * Participant submits, facilitator approves.

3. **Solution generation**

   * Solution Agent produces solutions. Facilitator can regenerate or refine.

4. **Debate and rebuttal**

   * Proponent Point 1 → Opponent Rebuttal 1 → votes captured.
   * Repeat for Points 2..N.
   * Participant questions can be submitted but are queued.

5. **Analysis**

   * Analyst attaches evidence to the exact points and answers top-voted questions.
   * Each claim includes a citation and confidence note.

6. **Summary**

   * Moderator synthesises with sentiment and decision prompts.
   * Facilitator edits and annotates.

7. **Archive and output**

   * Save to Library with tags, debate map, exports to PDF or Markdown, and optional push to Miro, Mural, or Notion.

## UX and screen designs

### Session setup

* Grounding manager: drag-and-drop files, link capture, indexing progress.
* Tone controls: per-agent sliders with presets.
* Research mode toggle and rebuttal configuration (points per side, rounds).

### Solution view

* Numbered solutions with quick win and longer play variants.
* ‘Regenerate’, ‘Refine’, and ‘Proceed to debate’.

### Debate view

* Threaded conversation layout per point and rebuttal.
* Vote chips on each argument.
* Evidence pins appear when the Analyst attaches sources.
* Floating ‘View debate map’ button.

### Summary view

* Moderator summary with sections for pros, cons, evidence, sentiment, and next steps.
* Inline edit and annotation controls.
* Export choices and archive controls.

### Debate map

* Flow chart: Solution node → pro branches → opposing branches overlaid → evidence nodes attached to claims.
* Hover to view claim text, source, and confidence.
* Toggle to show only highest-voted paths.

### Library

* Search and filters by tags, outcomes, workshop, research mode, and engagement score.
* Cards show problem statement, solution count, last updated, and quick links.

## Analytics and success metrics

* Cycle time, proportion of Quick vs Deep runs, regeneration rate by agent.
* Argument engagement: votes per point, top-voted claims, sentiment trend.
* Library utilisation: searches, revisits, exports, solutions adopted.
* Quality measures: facilitator rating of usefulness and accuracy.

## MVP scope

* Must have

  * Session setup with grounding uploads and tone presets.
  * Solution generation, rebuttal rounds, queued participant questions, Analyst evidence with citations.
  * Moderator summary with edit and annotate.
  * Visual debate map v1, argument voting, and Library with basic filters.
  * Exports to PDF and Markdown, captions for audio.

* Nice to have

  * Distinct voices per agent, confidence sliders per agent, outcome tracking, Notion or Miro export, advanced Library filters, and debate map filtering by engagement.

## Risks and mitigations

* **Irrelevant sources**

  * Strict grounding priority, connector allow-list, and evidence confidence thresholds.
* **Slow cycles in Deep mode**

  * Parallel retrieval, caching of grounding embeddings, and time-boxed search.
* **Low-quality solutions**

  * Regenerate with guided prompts and quick win vs long-term templates.
* **Overlong text outputs**

  * Enforced structure and length bands per section.

## Acceptance criteria

* Agents always respect grounding priority and research mode.
* Rebuttal rounds execute in the configured order without interruption.
* Analyst claims render with citations and confidence notes tied to the exact argument.
* Moderator summary supports edit and annotate before export.
* Debate map shows point, rebuttal, and evidence relationships.
* Library stores sessions with versioning and supports search and filters.

---
